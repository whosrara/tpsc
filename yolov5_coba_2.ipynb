{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whosrara/tpsc/blob/main/yolov5_coba_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkUAJWlfu2mP"
      },
      "source": [
        "# Playground (work)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q8bMANGBvYh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbjNDFqFu2mS",
        "outputId": "1e6d4181-a5f1-4f9d-8efb-6f1a1a8d9380"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2023-8-17 Python-3.11.5 torch-2.1.0+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
        "\n",
        "# Dictionary to store information about tracked vehicles\n",
        "tracked_vehicles = defaultdict(lambda: {'frame_count': 0, 'time_visible': 0, 'bbox': None})\n",
        "\n",
        "# Function to calculate Intersection over Union (IoU)\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    iou = interArea / float(box1Area + box2Area - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "# Function to count vehicles in a frame and update tracking information\n",
        "def count_and_track_vehicles(frame, fps):\n",
        "    results = model(frame)\n",
        "    vehicle_classes = ['car', 'motorcycle']  # Define vehicle classes\n",
        "    vehicles = [x for x in results.pred[0] if results.names[int(x[5])] in vehicle_classes]\n",
        "\n",
        "    current_frame_vehicles = {}\n",
        "\n",
        "    for *box, _, class_id in vehicles:\n",
        "        label = results.names[int(class_id)]\n",
        "        box = list(box)\n",
        "\n",
        "        best_match_id = None\n",
        "        best_iou = 0\n",
        "        for vehicle_id, data in tracked_vehicles.items():\n",
        "            iou = calculate_iou(data['bbox'], box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_match_id = vehicle_id\n",
        "\n",
        "        if best_match_id and best_iou > 0.5:  # IoU threshold\n",
        "            tracked_vehicles[best_match_id]['frame_count'] += 1\n",
        "            tracked_vehicles[best_match_id]['bbox'] = box\n",
        "            vehicle_id = best_match_id\n",
        "        else:\n",
        "            vehicle_id = len(tracked_vehicles) + 1\n",
        "            tracked_vehicles[vehicle_id] = {'frame_count': 1, 'bbox': box, 'label': label}\n",
        "\n",
        "        tracked_vehicles[vehicle_id]['time_visible'] = tracked_vehicles[vehicle_id]['frame_count'] / fps\n",
        "        current_frame_vehicles[vehicle_id] = tracked_vehicles[vehicle_id]\n",
        "\n",
        "        cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"{label} - {tracked_vehicles[vehicle_id]['time_visible']:.2f} sec\", (int(box[0]), int(box[1]-10)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return len(current_frame_vehicles), current_frame_vehicles, results\n",
        "\n",
        "# Process video\n",
        "# video = cv2.VideoCapture('v.mp4')\n",
        "video = cv2.VideoCapture('j.mp4')\n",
        "fps = video.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "\n",
        "while video.isOpened():\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    vehicle_count, current_frame_vehicles, results = count_and_track_vehicles(frame, fps)\n",
        "\n",
        "    cv2.putText(frame, f'Tracked Vehicles: {vehicle_count}', (10, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    # for vehicle_id, data in current_frame_vehicles.items():\n",
        "    #     time_visible = data['time_visible']\n",
        "    #     cv2.putText(frame, f'ID {vehicle_id}: {time_visible:.2f} sec', (10, 60 + 30 * vehicle_id), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yidyTKI7u2mV"
      },
      "source": [
        "# Playground 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Fk8BSBu2mV",
        "outputId": "5323075c-e6e4-4907-ce32-17deb9a5ac79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2023-8-17 Python-3.11.5 torch-2.1.0+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
        "\n",
        "# Dictionary to store information about tracked vehicles with grace period feature\n",
        "grace_period = 10  # Number of frames a vehicle can be untracked before being removed\n",
        "tracked_vehicles = defaultdict(lambda: {'frame_count': 0, 'time_visible': 0, 'bbox': None, 'grace_counter': grace_period})\n",
        "\n",
        "# Function to calculate Intersection over Union (IoU)\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    iou = interArea / float(box1Area + box2Area - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "# Function to count vehicles in a frame and update tracking information with grace period logic\n",
        "def count_and_track_vehicles(frame, fps):\n",
        "    results = model(frame)\n",
        "    vehicle_classes = ['car', 'motorcycle']  # Define vehicle classes\n",
        "    vehicles = [x for x in results.pred[0] if results.names[int(x[5])] in vehicle_classes]\n",
        "\n",
        "    # Decrease grace period counters for all tracked vehicles\n",
        "    for vehicle_id in list(tracked_vehicles.keys()):\n",
        "        tracked_vehicles[vehicle_id]['grace_counter'] -= 1\n",
        "        if tracked_vehicles[vehicle_id]['grace_counter'] <= 0:\n",
        "            del tracked_vehicles[vehicle_id]\n",
        "\n",
        "    current_frame_vehicles = {}\n",
        "\n",
        "    for *box, _, class_id in vehicles:\n",
        "        label = results.names[int(class_id)]\n",
        "        box = list(map(int, box))\n",
        "\n",
        "        best_match_id = None\n",
        "        best_iou = 0\n",
        "        for vehicle_id, data in tracked_vehicles.items():\n",
        "            iou = calculate_iou(data['bbox'], box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_match_id = vehicle_id\n",
        "\n",
        "        if best_match_id and best_iou > 0.5:  # IoU threshold\n",
        "            tracked_vehicles[best_match_id]['frame_count'] += 1\n",
        "            tracked_vehicles[best_match_id]['bbox'] = box\n",
        "            tracked_vehicles[best_match_id]['grace_counter'] = grace_period\n",
        "            vehicle_id = best_match_id\n",
        "        else:\n",
        "            vehicle_id = len(tracked_vehicles) + 1\n",
        "            tracked_vehicles[vehicle_id] = {'frame_count': 1, 'bbox': box, 'label': label, 'grace_counter': grace_period}\n",
        "\n",
        "        # Adjusting the frame count for skipped frames\n",
        "        adjusted_frame_count = tracked_vehicles[vehicle_id]['frame_count'] * frame_skip\n",
        "\n",
        "        # Calculating time visible with adjusted frame count\n",
        "        tracked_vehicles[vehicle_id]['time_visible'] = adjusted_frame_count / fps\n",
        "\n",
        "        current_frame_vehicles[vehicle_id] = tracked_vehicles[vehicle_id]\n",
        "\n",
        "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"{label} - {tracked_vehicles[vehicle_id]['time_visible']:.2f} sec\", (box[0], box[1] - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return len(current_frame_vehicles), current_frame_vehicles, results\n",
        "\n",
        "# Process video\n",
        "video = cv2.VideoCapture('v.mp4')\n",
        "fps = video.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "\n",
        "frame_skip = 2  # Skip every 2 frames\n",
        "frame_count = 0\n",
        "\n",
        "while video.isOpened():\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % frame_skip != 0:\n",
        "        continue  # Skip this frame\n",
        "\n",
        "    vehicle_count, current_frame_vehicles, results = count_and_track_vehicles(frame, fps)\n",
        "\n",
        "    cv2.putText(frame, f'Tracked Vehicles: {vehicle_count}', (10, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFv8gW_tu2mX"
      },
      "source": [
        "# DUMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHsApihGu2mX",
        "outputId": "ece5204f-0935-4f9e-d920-edca68102202"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2023-8-17 Python-3.11.5 torch-2.1.0+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Dictionary to store information about tracked vehicles\n",
        "tracked_vehicles = defaultdict(lambda: {'frame_count': 0, 'time_visible': 0, 'bbox': None})\n",
        "\n",
        "# Function to calculate Intersection over Union (IoU)\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    iou = interArea / float(box1Area + box2Area - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "# Function to count vehicles in a frame and update tracking information\n",
        "def count_and_track_vehicles(frame, fps):\n",
        "    results = model(frame)\n",
        "    vehicle_classes = ['car', 'motorcycle']  # Define vehicle classes\n",
        "    vehicles = [x for x in results.pred[0] if results.names[int(x[5])] in vehicle_classes]\n",
        "\n",
        "    current_frame_vehicles = {}\n",
        "\n",
        "    for *box, _, class_id in vehicles:\n",
        "        label = results.names[int(class_id)]\n",
        "        box = list(map(int, box))\n",
        "\n",
        "        best_match_id = None\n",
        "        best_iou = 0\n",
        "        for vehicle_id, data in tracked_vehicles.items():\n",
        "            iou = calculate_iou(data['bbox'], box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_match_id = vehicle_id\n",
        "\n",
        "        if best_match_id and best_iou > 0.5:  # IoU threshold\n",
        "            tracked_vehicles[best_match_id]['frame_count'] += 1\n",
        "            tracked_vehicles[best_match_id]['bbox'] = box\n",
        "            vehicle_id = best_match_id\n",
        "        else:\n",
        "            vehicle_id = len(tracked_vehicles) + 1\n",
        "            tracked_vehicles[vehicle_id] = {'frame_count': 1, 'bbox': box, 'label': label}\n",
        "\n",
        "        tracked_vehicles[vehicle_id]['time_visible'] = tracked_vehicles[vehicle_id]['frame_count'] / fps\n",
        "\n",
        "        # Check if the vehicle has been visible for more than 60 seconds\n",
        "        if tracked_vehicles[vehicle_id]['time_visible'] > 60:\n",
        "            bbox_color = (0, 0, 255)  # Red color for more than 1 minute\n",
        "        else:\n",
        "            bbox_color = (0, 255, 0)  # Green color for less than 1 minute\n",
        "\n",
        "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), bbox_color, 2)\n",
        "        cv2.putText(frame, f\"{label} - {tracked_vehicles[vehicle_id]['time_visible']:.2f} sec\",\n",
        "                    (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
        "\n",
        "        current_frame_vehicles[vehicle_id] = tracked_vehicles[vehicle_id]\n",
        "\n",
        "    return len(current_frame_vehicles), current_frame_vehicles, results\n",
        "\n",
        "# Process video\n",
        "# video = cv2.VideoCapture('j.mp4')\n",
        "video = cv2.VideoCapture('v.mp4')\n",
        "fps = video.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "\n",
        "while video.isOpened():\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    vehicle_count, current_frame_vehicles, results = count_and_track_vehicles(frame, fps)\n",
        "\n",
        "    # Check for starvation and count vehicles visible for over 60 seconds\n",
        "    starvation = False\n",
        "    starvation_count = 0\n",
        "    for vehicle_id, data in current_frame_vehicles.items():\n",
        "        if data['time_visible'] > 60:\n",
        "            starvation = True\n",
        "            starvation_count += 1\n",
        "\n",
        "    # Display tracked vehicles count\n",
        "    cv2.putText(frame, f'Tracked Vehicles: {vehicle_count}', (10, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "    # Display starvation information on the bottom right\n",
        "    cv2.putText(frame, f\"Starvation: {starvation} (Count: {starvation_count})\", (800, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6uZ9KK5u2mY"
      },
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH7yR4NOu2mY",
        "outputId": "7c69cbdd-f9ca-4389-ce2d-1b96fa5c7c54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2023-8-17 Python-3.11.5 torch-2.1.0+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
        "\n",
        "# Dictionary to store information about tracked vehicles\n",
        "tracked_vehicles = defaultdict(lambda: {'frame_count': 0, 'time_visible': 0, 'bbox': None})\n",
        "\n",
        "# Function to calculate Intersection over Union (IoU)\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    iou = interArea / float(box1Area + box2Area - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "# Function to count vehicles in a frame and update tracking information\n",
        "def count_and_track_vehicles(frame, fps):\n",
        "    results = model(frame)\n",
        "    vehicle_classes = ['car', 'motorcycle']  # Define vehicle classes\n",
        "    vehicles = [x for x in results.pred[0] if results.names[int(x[5])] in vehicle_classes]\n",
        "\n",
        "    current_frame_vehicles = {}\n",
        "\n",
        "    for *box, _, class_id in vehicles:\n",
        "        label = results.names[int(class_id)]\n",
        "        box = list(map(int, box))\n",
        "\n",
        "        best_match_id = None\n",
        "        best_iou = 0\n",
        "        for vehicle_id, data in tracked_vehicles.items():\n",
        "            iou = calculate_iou(data['bbox'], box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_match_id = vehicle_id\n",
        "\n",
        "        if best_match_id and best_iou > 0.5:  # IoU threshold\n",
        "            tracked_vehicles[best_match_id]['frame_count'] += 1\n",
        "            tracked_vehicles[best_match_id]['bbox'] = box\n",
        "            vehicle_id = best_match_id\n",
        "        else:\n",
        "            vehicle_id = len(tracked_vehicles) + 1\n",
        "            tracked_vehicles[vehicle_id] = {'frame_count': 1, 'bbox': box, 'label': label}\n",
        "\n",
        "        tracked_vehicles[vehicle_id]['time_visible'] = tracked_vehicles[vehicle_id]['frame_count'] / fps\n",
        "\n",
        "        # Check if the vehicle has been visible for more than 60 seconds\n",
        "        if tracked_vehicles[vehicle_id]['time_visible'] > 60:\n",
        "            bbox_color = (0, 0, 255)  # Red color for more than 1 minute\n",
        "        else:\n",
        "            bbox_color = (0, 255, 0)  # Green color for less than 1 minute\n",
        "\n",
        "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), bbox_color, 2)\n",
        "        cv2.putText(frame, f\"{label} - {tracked_vehicles[vehicle_id]['time_visible']:.2f} sec\",\n",
        "                    (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
        "\n",
        "        current_frame_vehicles[vehicle_id] = tracked_vehicles[vehicle_id]\n",
        "\n",
        "    return len(current_frame_vehicles), current_frame_vehicles, results\n",
        "\n",
        "# Process video\n",
        "video = cv2.VideoCapture('j.mp4')\n",
        "# video = cv2.VideoCapture('v.mp4')\n",
        "fps = video.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi', fourcc, fps, (int(video.get(3)), int(video.get(4))))\n",
        "\n",
        "while video.isOpened():\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    vehicle_count, current_frame_vehicles, results = count_and_track_vehicles(frame, fps)\n",
        "\n",
        "    # Check for starvation and count vehicles visible for over 60 seconds\n",
        "    starvation = False\n",
        "    starvation_count = 0\n",
        "    for vehicle_id, data in current_frame_vehicles.items():\n",
        "        if data['time_visible'] > 60:\n",
        "            starvation = True\n",
        "            starvation_count += 1\n",
        "\n",
        "    # Display tracked vehicles count\n",
        "    cv2.putText(frame, f'Tracked Vehicles: {vehicle_count}', (10, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "    # Display starvation information on the bottom right\n",
        "    cv2.putText(frame, f\"Starvation: {starvation} (Count: {starvation_count})\", (800, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Write the frame with annotations to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the VideoWriter and VideoCapture objects\n",
        "out.release()\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lr4OtKu2mZ",
        "outputId": "37273dae-ddf5-47be-840a-724bbeb3485e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 4.5 MB/s eta 0:00:00\n",
            "Collecting Pillow>=10.0.1\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 19.0 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 146.1 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, Pillow, gitdb, gitpython\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 8.9s, installed 2 packages: ['gitpython>=3.1.30', 'Pillow>=10.0.1']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2023-12-14 Python-3.10.12 torch-2.1.0+cu118 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
            "100%|██████████| 40.8M/40.8M [00:00<00:00, 190MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
        "\n",
        "# Dictionary to store information about tracked vehicles\n",
        "tracked_vehicles = defaultdict(lambda: {'frame_count': 0, 'time_visible': 0, 'bbox': None})\n",
        "\n",
        "# Function to calculate Intersection over Union (IoU)\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[0], box2[0])\n",
        "    yA = max(box1[1], box2[1])\n",
        "    xB = min(box1[2], box2[2])\n",
        "    yB = min(box1[3], box2[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    iou = interArea / float(box1Area + box2Area - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "# Definisikan koordinat untuk area yang ingin diproses\n",
        "process_area = np.array([(316, 630), (708, 643), (662, 176), (489, 174)])\n",
        "\n",
        "# Fungsi untuk memeriksa apakah titik berada di dalam area yang ditentukan\n",
        "def is_point_in_area(point, area):\n",
        "    return cv2.pointPolygonTest(area, (point[0], point[1]), False) >= 0\n",
        "\n",
        "# Function to count vehicles in a frame and update tracking information\n",
        "def count_and_track_vehicles(frame, fps):\n",
        "    results = model(frame)\n",
        "    vehicle_classes = ['car', 'motorcycle']  # Define vehicle classes\n",
        "    vehicles = [x for x in results.pred[0] if results.names[int(x[5])] in vehicle_classes]\n",
        "\n",
        "    current_frame_vehicles = {}\n",
        "\n",
        "    for *box, _, class_id in vehicles:\n",
        "        label = results.names[int(class_id)]\n",
        "        box = list(map(int, box))\n",
        "\n",
        "        center_point = [(box[0] + box[2]) // 2, (box[1] + box[3]) // 2]\n",
        "        if not is_point_in_area(center_point, process_area):\n",
        "            continue  # Skip if not within specified area\n",
        "\n",
        "        best_match_id = None\n",
        "        best_iou = 0\n",
        "        for vehicle_id, data in tracked_vehicles.items():\n",
        "            iou = calculate_iou(data['bbox'], box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_match_id = vehicle_id\n",
        "\n",
        "        if best_match_id and best_iou > 0.5:  # IoU threshold\n",
        "            tracked_vehicles[best_match_id]['frame_count'] += 1\n",
        "            tracked_vehicles[best_match_id]['bbox'] = box\n",
        "            vehicle_id = best_match_id\n",
        "        else:\n",
        "            vehicle_id = len(tracked_vehicles) + 1\n",
        "            tracked_vehicles[vehicle_id] = {'frame_count': 1, 'bbox': box, 'label': label}\n",
        "\n",
        "        tracked_vehicles[vehicle_id]['time_visible'] = tracked_vehicles[vehicle_id]['frame_count'] / fps\n",
        "\n",
        "        if tracked_vehicles[vehicle_id]['time_visible'] > 60:\n",
        "            bbox_color = (0, 0, 255)  # Red for more than 1 minute\n",
        "        else:\n",
        "            bbox_color = (0, 255, 0)  # Green for less than 1 minute\n",
        "\n",
        "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), bbox_color, 2)\n",
        "        cv2.putText(frame, f\"{label} - {tracked_vehicles[vehicle_id]['time_visible']:.2f} sec\",\n",
        "                    (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
        "\n",
        "        current_frame_vehicles[vehicle_id] = tracked_vehicles[vehicle_id]\n",
        "\n",
        "    return len(current_frame_vehicles), current_frame_vehicles, results\n",
        "\n",
        "# Process video\n",
        "video = cv2.VideoCapture('j.mp4')\n",
        "fps = video.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi', fourcc, fps, (int(video.get(3)), int(video.get(4))))\n",
        "\n",
        "while video.isOpened():\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    vehicle_count, current_frame_vehicles, results = count_and_track_vehicles(frame, fps)\n",
        "\n",
        "    # Check for starvation and count vehicles visible for over 60 seconds\n",
        "    starvation = False\n",
        "    starvation_count = 0\n",
        "    for vehicle_id, data in current_frame_vehicles.items():\n",
        "        if data['time_visible'] > 60:\n",
        "            starvation = True\n",
        "            starvation_count += 1\n",
        "\n",
        "    # Display tracked vehicles count\n",
        "    cv2.putText(frame, f'Tracked Vehicles: {vehicle_count}', (10, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # Display starvation information on the bottom right\n",
        "    cv2.putText(frame, f\"Starvation: {starvation} (Count: {starvation_count})\", (800, 650), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Draw process area\n",
        "    cv2.polylines(frame, [process_area], True, (255, 255, 255), 3)  # White lines\n",
        "\n",
        "    # Write the frame with annotations to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    cv2.imshow('Frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the VideoWriter and VideoCapture objects\n",
        "out.release()\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQbFyTyu2ma"
      },
      "source": [
        "# POINT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6AOaOeju2ma",
        "outputId": "0f7ce41c-1cc9-4f3a-9e64-d45e7b734ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Koordinat titik yang dipilih: [(316, 630), (708, 643), (662, 176), (489, 174)]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Fungsi callback untuk menangani klik mouse\n",
        "def click_event(event, x, y, flags, params):\n",
        "    if event == cv2.EVENT_LBUTTONDOWN:\n",
        "        # Menyimpan koordinat ketika mouse diklik\n",
        "        points.append((x, y))\n",
        "\n",
        "        # Menampilkan titik yang telah diklik pada frame\n",
        "        cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "        # Jika sudah ada 4 titik, tampilkan koordinatnya\n",
        "        if len(points) == 4:\n",
        "            print(\"Koordinat titik yang dipilih:\", points)\n",
        "\n",
        "# Load video\n",
        "video = cv2.VideoCapture('j.mp4')\n",
        "\n",
        "# Baca frame pertama dari video\n",
        "ret, frame = video.read()\n",
        "\n",
        "if not ret:\n",
        "    print(\"Gagal membaca video\")\n",
        "    video.release()\n",
        "else:\n",
        "    # Buat jendela untuk menampilkan frame\n",
        "    cv2.namedWindow(\"Frame\")\n",
        "    cv2.setMouseCallback(\"Frame\", click_event)\n",
        "\n",
        "    points = []  # Untuk menyimpan koordinat titik yang dipilih\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # Tutup semua jendela dan release video setelah selesai\n",
        "    cv2.destroyAllWindows()\n",
        "    video.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuEZRlEwu2ma"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}